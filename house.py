# -*- coding: utf-8 -*-
"""House

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a_-zkpyCRAzS_TpMMmm_6t-Dfr4p1uHO
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Colab Notebooks/DataMining/Study/DataMining

!git config --global user.email 'gksdusql94@gmail.com'
!git config --global user.name 'gksdusql94'

!git add PythonDataHandling.ipynb

!git commit -m '원하는 아무 메시지'
!git push

"""# Predicting Home Prices

The [Ames Housing Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview) was introduced by Professor Dean De Cock in 2011 for use in data science education. It contains 2,919 observations of housing sales in Ames, Iowa between 2006 and 2010. There are a total of 79 features describing each house's size, quality, area, age, and other miscellaneous attributes.

From Kaggle:

>Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.

"""

from google.colab import drive
drive.mount('/content/drive')

"""## 1. Overall Understanding of the Data
In this section, you will need to complete the following tasks:
- Load the dataset as a pandas data frame.
- Display key information of the data.
- Handle missing values.

1.1 In the cell below, import the `pandas` library and load file `train.csv` from the Ames housing dataset as a data frame.
"""

import numpy as np
import pandas as pd
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/DataMining/Study/train.csv", on_bad_lines='skip')
print(df)

"""1.2 Display the first 5 rows of the data frame."""

df.head(5)

"""1.3 Display the shape of the data frame and list all column names."""

# Print the shape of the data frame
print("Shape of the DataFrame:",df.shape)

# list all column names.
column_names = df.columns.tolist() #열 이름을 >> 리스트로 변환하는 메서드 입니다.
print("Column names:", column_names)

# Shape of the data frame
print(df.count(), len(df.columns))

"""1.4 Display the number of missing values in each column."""

missing_values = df.isnull().sum()

print("Number of missing values in each column:")
print(missing_values)

"""1.5 Remove all the columns that contain missing values."""

df_drop =df.dropna(axis=1)
print(df_drop.head())

"""## 2. Study Key Features

The total number of features seems overwhelming, so let's start with a few features that we know are definitely relevant:
1. `OverallQual`: Overall material and finish quality
2. `YearBuilt`: Original construction date
3. `TotalBsmtSF`: Total basement area in square feet
4. `GrLivArea`: Above ground living area in square feet

and don't forget `SalePrice`.

For each of these 5 features, please find:
- Descriptive statistics
- Graphical representation of their distribution
- Check for outliers
- Study correlations

2.1 **Descriptive statistics**: For each of the 5 features, find its minimum, maximum, mean, and standard deviation.
"""

#method 1
import pandas as pd
selected_columns = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea', 'SalePrice']
data = df[selected_columns]

statistics = data.describe()
print(statistics)

#method 2
min_values = data.min()
max_values = data.max()
mean_values = data.mean()
std_deviation = data.std()

print("Minimum values:")
print(min_values)
print("\nMaximum values:")
print(max_values)
print("\nMean values:")
print(mean_values)
print("\nStandard Deviation:")
print(std_deviation)

"""2.2 **Distribution**: For each of the 5 features, generate a histogram. Choose the number of bins properly."""

import pandas as pd
import matplotlib.pyplot as plt

selected_columns = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea', 'SalePrice']

for column in selected_columns:
    plt.figure(figsize=(5, 4))
    plt.hist(df[column], bins=15, color='blue', edgecolor='skyblue')
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.show()

"""2.3 **Outliers**: An **outlier** is a value that is located far away from the vast majority of the data. Remove those rows that contain outliers."""

lower_quantile = 0.05 # 5%
upper_quantile = 0.95

# Loop through the selected columns and remove outliers
for column in selected_columns:
    # Calculate lower and upper limits based on quantiles
    lower_limit = df[column].quantile(lower_quantile)
    upper_limit = df[column].quantile(upper_quantile)
    # Create a filter to identify rows without outliers
    filter = (df[column] >= lower_limit) & (df[column] <= upper_limit)

    # Apply the filter to the DataFrame to remove outliers
    df = df[filter] #너무 왜곡되지 않게제거하는 것.

"""2.4 **Correlation with sale price**: For each of the 4 chosen predictive features, draw a scatter plot of this feature and `SalePrice`. Set the title, axis label of the graph properly."""

selected_features = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea']
target_feature = 'SalePrice'
correlation_matrix = data.corr()

for feature in selected_features:
    plt.figure(figsize=(4, 3))
    plt.scatter(df[feature], df[target_feature], alpha=0.7, color='skyblue')
    plt.title(f'Scatter Plot of {feature} vs. {target_feature}')
    plt.xlabel(feature)
    plt.ylabel(target_feature)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.show()

"""Describe the correlation between each predictive feature and `SalePrice`. Is there a positive correclation, a negative correlation, or no correlation?"""

selected_features = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea']
target_feature = 'SalePrice'

correlations = df[selected_features + [target_feature]].corr() # 주어진 특징과 목표 특징 간의 상관 관계 계산

print(correlations)

"""## 3. Identify Additional Predictive Feature
Let’s find out if other features are helpful to the price prediction. Additional features can be identified in the following ways:
- Calculate correlation coefficient between `SalePrice` and an existing feature.
- Create new features from existing features.

3.1 Calculate the correlation coefficient of each feature with `SalePrice` (excluding `SalePrice` itself). Identify the feature (other than the 4 features studied in the previous section) that has the strongest correlation with the sale prices.
"""

remaining_features = [col for col in df.columns if col != target_feature] #목표 특성(SalePrice)을 제외한 특성['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea']

# Calculate correlation coefficients with 'SalePrice'
correlation_results = {}
for feature in remaining_features:
    if df[feature].dtype in ['int64', 'float64']:
      correlation = df[feature].corr(df[target_feature])
    correlation_results[feature] = correlation

# Find the feature with the strongest correlation
strongest_correlation_feature = max(correlation_results, key=lambda k: abs(correlation_results[k]))
strongest_correlation_coefficient = correlation_results[strongest_correlation_feature]

print(f"The feature with the strongest correlation with SalePrice is '{strongest_correlation_feature}' with a correlation coefficient of {strongest_correlation_coefficient:.2f}.")

"""3.2 **Feature engineering**: Based on our experience, the total area of the house and the average area per room should also be important factors in determining the price. Please create these two columns using the following formula:

1. total area = total area above ground (“GrLivArea”) + total basement area (“TotalBsmtSF”)
2. area per room = total area above ground (“GrLivArea”) / number of rooms (“TotRmsAbvGrd”).

"""

df['TotalArea'] = df['GrLivArea'] + df['TotalBsmtSF']

df['AreaPerRoom'] = df['GrLivArea'] / df['TotRmsAbvGrd']
print(df[['TotalArea', 'AreaPerRoom']].head())

"""Up to this point, you should have obtained 7 features that are helpful to predict the sale price: `OverallQual`, `YearBuilt`, `TotalBasmtSF`, `GrLivArea`, `TotalArea`, `AreaPerRoom`, and a feature selected in 3.1. Create a new data frame with `SalePrice` and these 7 features only. Save the data as a CSV file named `HousingData_processed.csv` on your computer."""

selected_features = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea', 'TotalArea', 'AreaPerRoom', strongest_correlation_feature]

df_processed = df[selected_features]
df_processed.to_csv("HousingData_processed.csv", index=False)

print("Data has been saved as HousingData_processed.csv")

"""## 4. Calculate Feature Statistics

Let's apply the **k-nearest-neighbor method** to this dataset and estimate the price of a house in the test set:

- OverallQual: 5
- YearBuilt: 1961
- TotalBsmtSF: 882
- GrLivArea: 896

Additional information about this house is on the first row of `test.csv`. The ID of this house in the data set is 1461.

The core idea of the k-nearest-neighbor method is to find existing houses that are most similar to the house with unknown price. Since similar houses should be priced similarly, their average price can be used as a good estimate on the price of the new house.

In order to conduct this estimation, we need to normalize the columns using the mean value and the standard deviation of each of the seven predictive features. These features include `OverallQual`, `YearBuilt`, `TotalBsmtSF`, `GrLivArea`, `TotalArea`, `AreaPerRoom`, and the feature you selected using correlation coefficient.

Transform each column with the following formula:
$$ \textit{normalized value} = \frac{\textit{original value} - mean}{\textit{standard deviation}}$$
"""

import pandas as pd
import numpy as np

train_df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/DataMining/Study/train.csv")
test_df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/DataMining/Study/test.csv")

new_house_info = {'OverallQual': 5,'YearBuilt': 1961,'TotalBsmtSF': 882,'GrLivArea': 896} # k-nearest-neighbor method

additional_feature = strongest_correlation_feature
selected_features = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea', additional_feature, 'SalePrice']

for feature in selected_features[:-1]:  # Exclude 'SalePrice'
    mean_value = train_df[feature].mean()
    std_deviation = train_df[feature].std()
    new_house_info[feature] = (new_house_info[feature] - mean_value) / std_deviation

# Calculate Euclidean distances between the new house and all houses in the training set
train_features = train_df[selected_features[:-1]].values  # Exclude 'SalePrice'
new_house_features = np.array([new_house_info[feature] for feature in selected_features[:-1]])  # Exclude 'SalePrice'
distances = np.linalg.norm(train_features - new_house_features, axis=1)

k = 5

k_nearest_indices = np.argsort(distances)[:k] #오름차순으로 정리후 정렬값을 반환(처음 k개 만을 반환)

average_price = train_df.iloc[k_nearest_indices]['SalePrice'].mean()
print(f"The estimated price of the new house (ID 1461) is ${average_price:.2f}")

"""5. Measure Difference

For each house in the data frame, measure its difference to the target house by summing up the squared difference on each predictive feature. Write this value in a new column named Diff.

Display the difference for the first 5 houses below:
"""

target_house_info = {'OverallQual': 5, 'YearBuilt': 1961,'TotalBsmtSF': 882, 'GrLivArea': 896}
selected_features = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea']

squared_diff = ((df[selected_features] - pd.Series(target_house_info))[selected_features] ** 2).sum(axis=1)

df['Diff'] = squared_diff
print(df[['Id', 'Diff']].head(5))

"""## 6. Find Nearest Neighbors

Find 5 houses that are the most similar to the target house.

List their prices below.
"""

nearest_neighbors = df.nsmallest(5, 'Diff')

similar_prices = nearest_neighbors['SalePrice'].tolist()

print("Prices of 5 most similar houses:")
for n, price in enumerate(similar_prices, start=1): print(f"House {n}: ${price:.2f}")

"""## 7. Make Predictions

The prediction on the price of the new house is the average price of the 5 houses listed above. Display the predicted price below.
"""

predicted_price = nearest_neighbors['SalePrice'].mean()

print(f"Predicted Price of the Target House: ${predicted_price:.2f}")